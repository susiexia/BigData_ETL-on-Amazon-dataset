{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_NPLPipeline_MLmodel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOB+KlWQZjWVHjg7XrQtqOk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/susiexia/BigData_ETL-on-Amazon-dataset/blob/master/pyspark_NPLPipeline_MLmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41jxUpJXFK3L",
        "colab_type": "text"
      },
      "source": [
        "A pipeline enables us to store all of the functions we have created in different stages and run only once. The output of one stage is passed on to the next one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYlS30JvFVlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Java, Spark, and Findspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# start a  Spark.sql.Session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Yelp_NLP').getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvHd5CIsFDo2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "d2b6e675-3ef3-4159-fa3c-11895ae5835f"
      },
      "source": [
        "# read in data from aws S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "\n",
        "url= \"https://s3.amazonaws.com/dataviz-curriculum/day_2/yelp_reviews.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get('yelp_reviews.csv'), sep=',', header=True)\n",
        "df.show(truncate=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------------------------------------------------------------------------------------------------------------+\n",
            "|class   |text                                                                                                           |\n",
            "+--------+---------------------------------------------------------------------------------------------------------------+\n",
            "|positive|Wow... Loved this place.                                                                                       |\n",
            "|negative|Crust is not good.                                                                                             |\n",
            "|negative|Not tasty and the texture was just nasty.                                                                      |\n",
            "|positive|Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.                        |\n",
            "|positive|The selection on the menu was great and so were the prices.                                                    |\n",
            "|negative|Now I am getting angry and I want my damn pho.                                                                 |\n",
            "|negative|Honeslty it didn't taste THAT fresh.)                                                                          |\n",
            "|negative|The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.|\n",
            "|positive|The fries were great too.                                                                                      |\n",
            "|positive|A great touch.                                                                                                 |\n",
            "|positive|Service was very prompt.                                                                                       |\n",
            "|negative|Would not go back.                                                                                             |\n",
            "|negative|The cashier had no care what so ever on what I had to say it still ended up being wayyy overpriced.            |\n",
            "|positive|I tried the Cape Cod ravoli, chicken,with cranberry...mmmm!                                                    |\n",
            "|negative|I was disgusted because I was pretty sure that was human hair.                                                 |\n",
            "|negative|I was shocked because no signs indicate cash only.                                                             |\n",
            "|positive|Highly recommended.                                                                                            |\n",
            "|negative|Waitress was a little slow in service.                                                                         |\n",
            "|negative|This place is not worth your time, let alone Vegas.                                                            |\n",
            "|negative|did not like at all.                                                                                           |\n",
            "+--------+---------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs19JYl-Kt_5",
        "colab_type": "text"
      },
      "source": [
        "Addtional function to use\n",
        "1. use StringIndexer function to convert 'class' string column to label indices, the labels will be what we'ar predict by LM\n",
        "2. use length function to add a column shows the length of each row, to be used as a future feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd5tprVTHc5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import ml.feature functions\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer, VectorAssembler\n",
        "from pyspark.sql.functions import length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfdWhYxdLB8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add a new column as a future feature\n",
        "df = df.withColumn('length', length(df.text))\n",
        "#data_df.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDOrd7ELMHVa",
        "colab_type": "text"
      },
      "source": [
        "Create all **transformations** stages to be applied in our pipeline\n",
        "\n",
        "*(stop by calling them by fit() and transform() function)*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La_s6ZAdMEEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create all the ml.features to df\n",
        "strIndexed = StringIndexer(inputCol='class', outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol='text', outputCol='tokened')\n",
        "stopremover = StopWordsRemover(inputCol='tokened', outputCol='removed')\n",
        "hashngTF = HashingTF(inputCol='removed', outputCol='hashed')\n",
        "idf = IDF(inputCol='hashed', outputCol='idf_token')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6yuh2wVO2mk",
        "colab_type": "text"
      },
      "source": [
        "create a **feature** **vector** containing the output from IDF and the length.\n",
        "\n",
        " This will combine all the raw features to train the ML model that weâ€™ll be using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyuLzDAPPOH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from pyspark.ml.linalg import Vector\n",
        "# create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzRcaJa1XjSo",
        "colab_type": "text"
      },
      "source": [
        "Create the pipeline and list the stages in the order they need to be executed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_qMEcdWXiRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages= [strIndexed, tokenizer, stopremover, hashngTF, idf, clean_up])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-Qa3MtObDdh",
        "colab_type": "text"
      },
      "source": [
        "**RUN** the Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSe9BHk0a8-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "57b53dfd-5675-4f63-ca29-235a0dac3d34"
      },
      "source": [
        "# fit model and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(df)    # produce a PipelineModel\n",
        "# use PipelineModel to transform orginal df\n",
        "cleaned = cleaner.transform(df)\n",
        "cleaned.select('label','features').show(truncate=False)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|label|features                                                                                                                                                                                                                                                                |\n",
            "+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|0.0  |(262145,[33933,69654,123604,262144],[4.51085950651685,6.215607598755275,3.8642323415917974,24.0])                                                                                                                                                                       |\n",
            "|1.0  |(262145,[150903,153353,262144],[3.7732605633860707,5.810142490647111,18.0])                                                                                                                                                                                             |\n",
            "|1.0  |(262145,[63367,115881,227406,262144],[5.52246041819533,6.215607598755275,4.962844630259907,41.0])                                                                                                                                                                       |\n",
            "|0.0  |(262145,[6286,27293,33933,53101,68727,76515,90362,140586,146390,188822,262144],[6.215607598755275,5.810142490647111,4.51085950651685,6.215607598755275,6.215607598755275,5.52246041819533,6.215607598755275,5.116995310087166,6.215607598755275,4.075541435259004,87.0])|\n",
            "|0.0  |(262145,[6979,91184,138356,151571,262144],[5.52246041819533,4.829313237635384,2.9197707327509463,4.6061696863211745,59.0])                                                                                                                                              |\n",
            "|1.0  |(262145,[24661,34140,98142,190256,255299,262144],[6.215607598755275,4.829313237635384,5.29931686688112,4.269697449699962,5.810142490647111,46.0])                                                                                                                       |\n",
            "|1.0  |(262145,[101702,228557,252339,262144],[4.711530201979001,6.215607598755275,6.215607598755275,37.0])                                                                                                                                                                     |\n",
            "|1.0  |(262145,[3645,85530,89720,121517,140784,144799,159927,189440,208258,262144],[6.215607598755275,4.962844630259907,5.810142490647111,3.3252358408591105,4.13616605707544,6.215607598755275,5.116995310087166,6.215607598755275,3.147554663621658,111.0])                  |\n",
            "|0.0  |(262145,[53777,138356,227926,262144],[5.29931686688112,2.9197707327509463,4.829313237635384,25.0])                                                                                                                                                                      |\n",
            "|0.0  |(262145,[138356,224853,262144],[2.9197707327509463,6.215607598755275,14.0])                                                                                                                                                                                             |\n",
            "|0.0  |(262145,[24113,209466,262144],[2.883403088580071,6.215607598755275,24.0])                                                                                                                                                                                               |\n",
            "|1.0  |(262145,[172477,195807,262144],[3.195182712610913,3.96431580014878,18.0])                                                                                                                                                                                               |\n",
            "|1.0  |(262145,[36200,40861,51520,65212,102978,109230,185473,203802,262144],[4.4238481295272205,5.810142490647111,5.810142490647111,4.343805421853684,6.215607598755275,5.810142490647111,5.810142490647111,3.730700948967275,99.0])                                           |\n",
            "|0.0  |(262145,[18098,83839,100079,111292,135859,243685,262144],[6.215607598755275,6.215607598755275,4.829313237635384,6.215607598755275,6.215607598755275,6.215607598755275,59.0])                                                                                            |\n",
            "|1.0  |(262145,[89493,95906,133777,134125,175449,262144],[6.215607598755275,5.810142490647111,6.215607598755275,4.829313237635384,3.96431580014878,62.0])                                                                                                                      |\n",
            "|1.0  |(262145,[86431,101445,129941,137657,159775,262144],[6.215607598755275,5.810142490647111,6.215607598755275,6.215607598755275,6.215607598755275,50.0])                                                                                                                    |\n",
            "|0.0  |(262145,[31704,215473,262144],[5.29931686688112,6.215607598755275,19.0])                                                                                                                                                                                                |\n",
            "|1.0  |(262145,[27707,65069,147752,181519,262144],[4.962844630259907,4.075541435259004,4.711530201979001,4.51085950651685,38.0])                                                                                                                                               |\n",
            "|1.0  |(262145,[12329,61231,64188,102787,115653,152959,262144],[6.215607598755275,2.5780214390288894,5.810142490647111,4.51085950651685,4.711530201979001,6.215607598755275,51.0])                                                                                             |\n",
            "|1.0  |(262145,[8287,208258,262144],[5.810142490647111,3.147554663621658,20.0])                                                                                                                                                                                                |\n",
            "+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D96Pq3ieZMo",
        "colab_type": "text"
      },
      "source": [
        "## RUN ML model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO6R--j3eqBk",
        "colab_type": "text"
      },
      "source": [
        "random split df into 70-30, 70% as training data will be passed to NLP model in order to train model to predict results. \n",
        "30% is testing data, to test our predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwqByhOfl_5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHk0_sNbekwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# break whole data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7,0.3])\n",
        "\n",
        "#create a Naive Bayes Model \n",
        "nb = NaiveBayes() \n",
        "predictor = nb.fit(training)     # fit training df to nb model, predictor is NaiveBayes object\n",
        "\n",
        "# transform the model with teasting data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.select('features', 'rawPrediction','probability','prediction').show(truncate= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZcJbuQOtLEE",
        "colab_type": "text"
      },
      "source": [
        "## evaluation the prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d3_Y5cAtGbG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ade29c4-abec-41a9-c868-c7e5e760f3ab"
      },
      "source": [
        "# use the Class Evaluator for a cleaner description\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "\n",
        "acc = acc_eval.evaluate(test_results)    # action (evaluate)\n",
        "\n",
        "print(\"Accuracy of model at predicting reviews was : %f \"% acc)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7272814799644581\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}